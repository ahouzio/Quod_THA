{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T19:06:29.177088Z",
     "iopub.status.busy": "2025-01-26T19:06:29.176734Z",
     "iopub.status.idle": "2025-01-26T19:06:29.402813Z",
     "shell.execute_reply": "2025-01-26T19:06:29.401919Z",
     "shell.execute_reply.started": "2025-01-26T19:06:29.177062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:16.826961Z",
     "iopub.status.busy": "2025-01-26T18:36:16.826650Z",
     "iopub.status.idle": "2025-01-26T18:36:19.282818Z",
     "shell.execute_reply": "2025-01-26T18:36:19.281888Z",
     "shell.execute_reply.started": "2025-01-26T18:36:16.826935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tr_1 = pd.read_csv(\"/kaggle/input/transaction-ds/transactions_1.csv\", index_col=0)\n",
    "tr_2 = pd.read_csv(\"/kaggle/input/transaction-ds/transactions_2.csv\", index_col=0)\n",
    "tr_total = pd.concat([tr_1, tr_2], axis = 0).sort_values(by = [\"date\"])\n",
    "tr_total = tr_total.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:19.284215Z",
     "iopub.status.busy": "2025-01-26T18:36:19.283967Z",
     "iopub.status.idle": "2025-01-26T18:36:22.548886Z",
     "shell.execute_reply": "2025-01-26T18:36:22.547961Z",
     "shell.execute_reply.started": "2025-01-26T18:36:19.284195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert date column to datetime\n",
    "tr_total['date'] = pd.to_datetime(tr_total['date'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce')\n",
    "\n",
    "tr_total['year'] = tr_total['date'].dt.to_period('Y') # Format: YYYY\n",
    "tr_total['year_month'] = tr_total['date'].dt.to_period('M')  # Format: YYYY-MM\n",
    "tr_total['year_month_day'] = tr_total['date'].dt.to_period('D')  # Format: YYYY-MM-DD\n",
    "tr_total['year_month_day_hour'] = tr_total['date'].dt.to_period('h')  # Format: YYYY-MM-DD HH\n",
    "monthly_data = tr_total.groupby(['customer_id', 'year_month'])['product_id'].count().reset_index().rename(columns = {\"product_id\" : \"transactions\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:22.550500Z",
     "iopub.status.busy": "2025-01-26T18:36:22.550202Z",
     "iopub.status.idle": "2025-01-26T18:36:22.565126Z",
     "shell.execute_reply": "2025-01-26T18:36:22.564327Z",
     "shell.execute_reply.started": "2025-01-26T18:36:22.550477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_dates = pd.period_range(start=monthly_data['year_month'].min(),\n",
    "                            end=monthly_data['year_month'].max(),\n",
    "                            freq='M')\n",
    "\n",
    "all_combinations = pd.MultiIndex.from_product(\n",
    "    [monthly_data['customer_id'].unique(), all_dates],\n",
    "    names=['customer_id', 'year_month']\n",
    ").to_frame(index=False)\n",
    "\n",
    "# Merge with the original data to fill in missing months\n",
    "complete_data = all_combinations.merge(monthly_data, on=['customer_id', 'year_month'], how='left')\n",
    "complete_data['transactions'] = complete_data['transactions'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complete_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complete_data[complete_data[\"customer_id\"] == 1001614].plot(\"year_month\", \"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complete_data[complete_data[\"customer_id\"] == 9997881].plot(\"year_month\", \"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:22.918606Z",
     "iopub.status.busy": "2025-01-26T18:36:22.918370Z",
     "iopub.status.idle": "2025-01-26T18:36:31.897034Z",
     "shell.execute_reply": "2025-01-26T18:36:31.896342Z",
     "shell.execute_reply.started": "2025-01-26T18:36:22.918587Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "targets = []\n",
    "\n",
    "for customer_id in complete_data['customer_id'].unique():\n",
    "    customer_data = complete_data[complete_data['customer_id'] == customer_id]\n",
    "    \n",
    "    for i in range(len(customer_data) - window_size + 1):\n",
    "        target_sum = customer_data['transactions'].iloc[i:i+window_size].sum()\n",
    "        \n",
    "        targets.append({\n",
    "            'customer_id': customer_id,\n",
    "            'start_year': customer_data['year_month'].iloc[i].year,\n",
    "            'start_month': customer_data['year_month'].iloc[i].month,\n",
    "            'end_year': customer_data['year_month'].iloc[i+window_size-1].year,\n",
    "            'end_month': customer_data['year_month'].iloc[i+window_size-1].month,\n",
    "            'transactions': target_sum\n",
    "        })\n",
    "\n",
    "targets_df = pd.DataFrame(targets)\n",
    "targets_df = targets_df.sort_values(by=['customer_id', 'start_year', 'start_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:31.898357Z",
     "iopub.status.busy": "2025-01-26T18:36:31.898091Z",
     "iopub.status.idle": "2025-01-26T18:36:31.931670Z",
     "shell.execute_reply": "2025-01-26T18:36:31.931082Z",
     "shell.execute_reply.started": "2025-01-26T18:36:31.898336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for lag in range(3, 31, 3):\n",
    "    targets_df[f'lag_{lag}'] = targets_df.groupby('customer_id')['transactions'].shift(lag).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transactions lags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "autocorrelations = []\n",
    "nlags = 40\n",
    "\n",
    "# Group by customer_id and calculate autocorrelation for each customer\n",
    "for customer, group in targets_df.groupby('customer_id'):\n",
    "    transactions = group['transactions'].values\n",
    "    if len(transactions) > 1: \n",
    "        acf_values = acf(transactions, nlags=nlags, fft=False)  # Calculate ACF for the first lags\n",
    "        autocorrelations.append(acf_values)\n",
    "\n",
    "# Average autocorrelation across customers\n",
    "average_autocorrelation = np.mean(autocorrelations, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(3, len(average_autocorrelation), 3), average_autocorrelation[3::3])\n",
    "plt.title('Average Autocorrelation Across Customers')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Create the heatmap with annotations\n",
    "sns.heatmap(\n",
    "    targets_df.corr(), \n",
    "    annot=True,        \n",
    "    fmt=\".2f\",          \n",
    "    cmap=\"coolwarm\",    \n",
    "    annot_kws={\"size\": 12}, \n",
    "    linewidths=0.5,     \n",
    "    square=True         \n",
    ")\n",
    "\n",
    "plt.title(\"Correlation Heatmap\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:31.933571Z",
     "iopub.status.busy": "2025-01-26T18:36:31.933265Z",
     "iopub.status.idle": "2025-01-26T18:36:31.943240Z",
     "shell.execute_reply": "2025-01-26T18:36:31.942595Z",
     "shell.execute_reply.started": "2025-01-26T18:36:31.933531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_year = 2019\n",
    "train_month = 1\n",
    "\n",
    "train = targets_df[\n",
    "    (targets_df['end_year'] < train_year) |\n",
    "    ((targets_df['end_year'] == train_year) & (targets_df['end_month'] <= train_month))\n",
    "]\n",
    "\n",
    "test = targets_df[\n",
    "    (targets_df['start_year'] == train_year) &\n",
    "    (targets_df['start_month'] == train_month + 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:31.944507Z",
     "iopub.status.busy": "2025-01-26T18:36:31.944295Z",
     "iopub.status.idle": "2025-01-26T18:36:31.949642Z",
     "shell.execute_reply": "2025-01-26T18:36:31.948871Z",
     "shell.execute_reply.started": "2025-01-26T18:36:31.944487Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['customer_id', 'start_year', 'start_month', 'end_year', 'end_month',\n",
       "        'transactions', 'lag_3', 'lag_6', 'lag_9', 'lag_12', 'lag_15', 'lag_18',\n",
       "        'lag_21', 'lag_24', 'lag_27', 'lag_30'],\n",
       "       dtype='object'),\n",
       " (46046, 16),\n",
       " (2002, 16))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns, train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:31.951206Z",
     "iopub.status.busy": "2025-01-26T18:36:31.950884Z",
     "iopub.status.idle": "2025-01-26T18:36:31.966300Z",
     "shell.execute_reply": "2025-01-26T18:36:31.965459Z",
     "shell.execute_reply.started": "2025-01-26T18:36:31.951173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feat_cols = ['customer_id', 'start_year', 'start_month', 'end_year', 'end_month',\n",
    "            'lag_3', 'lag_6', 'lag_9', 'lag_12', 'lag_15', 'lag_18', 'lag_21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T20:19:22.494092Z",
     "iopub.status.busy": "2025-01-26T20:19:22.493723Z",
     "iopub.status.idle": "2025-01-26T20:19:22.502122Z",
     "shell.execute_reply": "2025-01-26T20:19:22.501262Z",
     "shell.execute_reply.started": "2025-01-26T20:19:22.494063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Features and target for training\n",
    "X_train = train[feat_cols]\n",
    "y_train = train['transactions']\n",
    "\n",
    "# Features and target for testing\n",
    "X_test = test[feat_cols]\n",
    "y_test = test['transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T20:19:23.391038Z",
     "iopub.status.busy": "2025-01-26T20:19:23.390702Z",
     "iopub.status.idle": "2025-01-26T20:19:23.396350Z",
     "shell.execute_reply": "2025-01-26T20:19:23.395513Z",
     "shell.execute_reply.started": "2025-01-26T20:19:23.391012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46046, 12), (46046,), (2002, 12), (2002,))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mean of previous customer transactions\n",
    "* Previous three months transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mean_transactions = train.groupby('customer_id')['transactions'].mean().reset_index()\n",
    "mean_transactions.rename(columns={'transactions': 'mean_transactions'}, inplace=True)\n",
    "test_with_mean = test.merge(mean_transactions, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred_benchmark = test_with_mean['mean_transactions']\n",
    "\n",
    "# Compute evaluation metrics for the benchmark\n",
    "mae_benchmark = mean_absolute_error(y_test, y_pred_benchmark)\n",
    "rmse_benchmark = root_mean_squared_error(y_test, y_pred_benchmark)\n",
    "\n",
    "# Print the benchmark results\n",
    "print(\"Benchmark Results (Mean Prediction):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_benchmark:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "last_train_values = train[(train[\"end_year\"] == 2019) & (train[\"end_month\"] == 1)][\"transactions\"]\n",
    "\n",
    "# Compute evaluation metrics for the benchmark\n",
    "mae_benchmark_2 = mean_absolute_error(y_test, last_train_values)\n",
    "rmse_benchmark_2 = root_mean_squared_error(y_test, last_train_values)\n",
    "\n",
    "# Print the benchmark results\n",
    "print(\"Benchmark Results (Mean Prediction):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_benchmark_2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=5, random_state=42)  # cv=5 for 5-fold cross-validation\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get the indices of features with non-zero coefficients\n",
    "selected_features = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "print(f\"Number of selected features: {len(selected_features)}\")\n",
    "if hasattr(X_train, 'columns'):\n",
    "    print(\"Selected features:\", X_train.columns[selected_features])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_val, y_train_small, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_small, y_train_small)\n",
    "result = permutation_importance(rf, X_val, y_val, n_repeats=5, random_state=42, n_jobs=-1)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,  # Replace with feature names if available\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "})\n",
    "\n",
    "importance_df = importance_df.sort_values('importance_mean', ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'], importance_df['importance_mean'], xerr=importance_df['importance_std'])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Random Forest Permutation Importance (Validation Set)\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()\n",
    "\n",
    "selected_features = importance_df['feature'][:10]\n",
    "rf_final = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_final.fit(X_train[selected_features], y_train)\n",
    "test_score = rf_final.score(X_test[selected_features], y_test)\n",
    "print(f\"Test set R^2 score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T20:19:32.513630Z",
     "iopub.status.busy": "2025-01-26T20:19:32.513330Z",
     "iopub.status.idle": "2025-01-26T20:19:32.520612Z",
     "shell.execute_reply": "2025-01-26T20:19:32.519721Z",
     "shell.execute_reply.started": "2025-01-26T20:19:32.513603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "selected_features = [\"customer_id\",\"start_year\", \"start_month\", \"end_year\", \"end_month\", \"lag_3\", \"lag_6\", \"lag_9\", \"lag_12\", \"lag_15\"]\n",
    "X_train_selected = X_train.loc[:, selected_features]  \n",
    "X_test_selected = X_test.loc[:, selected_features]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:36:43.678190Z",
     "iopub.status.busy": "2025-01-26T18:36:43.677746Z",
     "iopub.status.idle": "2025-01-26T18:36:43.701116Z",
     "shell.execute_reply": "2025-01-26T18:36:43.700480Z",
     "shell.execute_reply.started": "2025-01-26T18:36:43.678156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n",
      "MAE: 40.7847780\n",
      "Testing Results:\n",
      "MAE: 22.0856233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9309e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train_selected, y_train)\n",
    "y_train_pred = ridge.predict(X_train_selected)\n",
    "y_test_pred = ridge.predict(X_test_selected)\n",
    "\n",
    "y_train_pred = np.clip(y_train_pred, 0, None)\n",
    "y_test_pred = np.clip(y_test_pred, 0, None)\n",
    "\n",
    "# Calculate MAE\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Training Results:\")\n",
    "print(f\"MAE: {train_mae:.7f}\")\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"MAE: {test_mae:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.concat([X_test, pd.Series(y_test, name = \"test\"), pd.Series(y_test_pred,  index=X_test.index, name=\"predictions\"), abs(y_test - y_test_pred)], axis = 1).rename(columns = {\"transactions\" : \"error\"}).sort_values(\"error\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complete_data[complete_data[\"customer_id\"] == 4893343].plot(\"year_month\", \"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "complete_data[complete_data[\"customer_id\"] == 6026638].plot(\"year_month\", \"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.5, color='blue', label='Predictions')\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=2, label='Ideal Fit')\n",
    "ax1.set_xlabel(\"Ground Truth (Training)\")\n",
    "ax1.set_ylabel(\"Predictions (Training)\")\n",
    "ax1.set_title(\"Training: Predictions vs. Ground Truth\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.5, color='red', label='Predictions')\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Ideal Fit')\n",
    "ax2.set_xlabel(\"Ground Truth (Testing)\")\n",
    "ax2.set_ylabel(\"Predictions (Testing)\")\n",
    "ax2.set_title(\"Testing: Predictions vs. Ground Truth\")\n",
    "ax2.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_selected.shape, X_test_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "            criterion=\"absolute_error\",\n",
    "            n_estimators = 80,\n",
    "            max_depth = 5,\n",
    "            max_features=\"sqrt\",\n",
    "            min_samples_split = 2,\n",
    "            n_jobs = -1,\n",
    "            random_state=42,\n",
    "            verbose = 1,\n",
    "        )\n",
    "\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train_selected)\n",
    "y_test_pred = model.predict(X_test_selected)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training MAE: {train_mae:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\") # 16.32 with 100, 16.4 with 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "most_important_tree_index = np.argmax([tree.tree_.impurity[0] for tree in model.estimators_])\n",
    "most_important_tree = model.estimators_[most_important_tree_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize the most important tree\n",
    "tree_dot = export_graphviz(\n",
    "    most_important_tree,\n",
    "    out_file=None,\n",
    "    feature_names=X_train_selected.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    "    impurity=True\n",
    ")\n",
    "\n",
    "# Render and display the tree inline in the notebook\n",
    "graph = Source(tree_dot)\n",
    "graph  # This will display the tree directly in the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:42:37.632844Z",
     "iopub.status.busy": "2025-01-26T18:42:37.632501Z",
     "iopub.status.idle": "2025-01-26T18:45:10.347058Z",
     "shell.execute_reply": "2025-01-26T18:45:10.345276Z",
     "shell.execute_reply.started": "2025-01-26T18:42:37.632777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-26 18:42:37,637] A new study created in memory with name: no-name-c6626dfb-b5b3-428d-a6fc-1bc44b24e219\n",
      "[I 2025-01-26 18:42:40,453] Trial 0 finished with value: 30.219685552228633 and parameters: {'max_depth': 6, 'colsample_bytree': 0.6206627670760091, 'min_child_weight': 10, 'learning_rate': 0.03500649452275317, 'num_boost_round': 266}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:43,622] Trial 1 finished with value: 37.931849451668725 and parameters: {'max_depth': 7, 'colsample_bytree': 0.5201628082958782, 'min_child_weight': 8, 'learning_rate': 0.0027731782274070223, 'num_boost_round': 163}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:44,334] Trial 2 finished with value: 39.88007588526343 and parameters: {'max_depth': 5, 'colsample_bytree': 0.6421023405469795, 'min_child_weight': 1, 'learning_rate': 0.005982018743932518, 'num_boost_round': 41}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:49,379] Trial 3 finished with value: 30.406614659389913 and parameters: {'max_depth': 10, 'colsample_bytree': 0.6237564763632444, 'min_child_weight': 10, 'learning_rate': 0.028032741610478574, 'num_boost_round': 282}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:49,938] Trial 4 finished with value: 41.61323432682826 and parameters: {'max_depth': 8, 'colsample_bytree': 0.5511340893307639, 'min_child_weight': 10, 'learning_rate': 0.0034647444626144056, 'num_boost_round': 19}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:56,673] Trial 5 finished with value: 30.782970164081284 and parameters: {'max_depth': 9, 'colsample_bytree': 0.7975209317537744, 'min_child_weight': 9, 'learning_rate': 0.00983197135306788, 'num_boost_round': 223}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:57,832] Trial 6 finished with value: 31.43600588209902 and parameters: {'max_depth': 3, 'colsample_bytree': 0.6575201406230335, 'min_child_weight': 5, 'learning_rate': 0.04146563984390162, 'num_boost_round': 95}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:42:59,198] Trial 7 finished with value: 36.03134536010883 and parameters: {'max_depth': 5, 'colsample_bytree': 0.9559256477272972, 'min_child_weight': 6, 'learning_rate': 0.006458630461495644, 'num_boost_round': 86}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:01,563] Trial 8 finished with value: 33.82388112823541 and parameters: {'max_depth': 9, 'colsample_bytree': 0.9857445962820431, 'min_child_weight': 8, 'learning_rate': 0.011450493012251912, 'num_boost_round': 72}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:08,466] Trial 9 finished with value: 33.50431517641433 and parameters: {'max_depth': 10, 'colsample_bytree': 0.7241760230071514, 'min_child_weight': 4, 'learning_rate': 0.0062597112464037995, 'num_boost_round': 162}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:09,492] Trial 10 finished with value: 30.525898520634883 and parameters: {'max_depth': 5, 'colsample_bytree': 0.853121903413038, 'min_child_weight': 2, 'learning_rate': 0.09099967448135841, 'num_boost_round': 279}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:12,732] Trial 11 finished with value: 30.226712614347576 and parameters: {'max_depth': 7, 'colsample_bytree': 0.6185488330595802, 'min_child_weight': 10, 'learning_rate': 0.027519690999489057, 'num_boost_round': 297}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:15,628] Trial 12 finished with value: 30.447701772467248 and parameters: {'max_depth': 6, 'colsample_bytree': 0.5791853638632356, 'min_child_weight': 7, 'learning_rate': 0.0257896625943085, 'num_boost_round': 227}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:20,253] Trial 13 finished with value: 38.967342417691256 and parameters: {'max_depth': 7, 'colsample_bytree': 0.7124874076767815, 'min_child_weight': 10, 'learning_rate': 0.0011489979557941904, 'num_boost_round': 232}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:22,759] Trial 14 finished with value: 30.417332840110287 and parameters: {'max_depth': 3, 'colsample_bytree': 0.5040108550625945, 'min_child_weight': 8, 'learning_rate': 0.07098652806793285, 'num_boost_round': 293}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:26,169] Trial 15 finished with value: 30.54620335440105 and parameters: {'max_depth': 6, 'colsample_bytree': 0.6014395575055119, 'min_child_weight': 4, 'learning_rate': 0.019452252804655804, 'num_boost_round': 254}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:28,630] Trial 16 finished with value: 30.27648240665703 and parameters: {'max_depth': 8, 'colsample_bytree': 0.6866696776769279, 'min_child_weight': 9, 'learning_rate': 0.050540589073709966, 'num_boost_round': 200}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:31,086] Trial 17 finished with value: 30.75271493591211 and parameters: {'max_depth': 4, 'colsample_bytree': 0.7898630141367469, 'min_child_weight': 6, 'learning_rate': 0.01589493534483575, 'num_boost_round': 192}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:33,064] Trial 18 finished with value: 30.400354981916415 and parameters: {'max_depth': 7, 'colsample_bytree': 0.7676918721816635, 'min_child_weight': 9, 'learning_rate': 0.04550497681421366, 'num_boost_round': 132}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:36,560] Trial 19 finished with value: 30.582679227191022 and parameters: {'max_depth': 8, 'colsample_bytree': 0.5644521435309637, 'min_child_weight': 7, 'learning_rate': 0.03126727444458557, 'num_boost_round': 262}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:37,833] Trial 20 finished with value: 30.43162336225991 and parameters: {'max_depth': 6, 'colsample_bytree': 0.846794956974674, 'min_child_weight': 10, 'learning_rate': 0.06705776781817797, 'num_boost_round': 260}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:40,493] Trial 21 finished with value: 30.538831890510153 and parameters: {'max_depth': 8, 'colsample_bytree': 0.6793108877008743, 'min_child_weight': 9, 'learning_rate': 0.04895863224994425, 'num_boost_round': 195}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:41,844] Trial 22 finished with value: 30.629107696829227 and parameters: {'max_depth': 8, 'colsample_bytree': 0.6888728715437835, 'min_child_weight': 9, 'learning_rate': 0.09801099027924046, 'num_boost_round': 298}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:47,373] Trial 23 finished with value: 30.464274705924304 and parameters: {'max_depth': 9, 'colsample_bytree': 0.6292674274180196, 'min_child_weight': 10, 'learning_rate': 0.017172735395905962, 'num_boost_round': 200}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:50,030] Trial 24 finished with value: 30.38618481783529 and parameters: {'max_depth': 7, 'colsample_bytree': 0.7380470130732792, 'min_child_weight': 8, 'learning_rate': 0.03566929075499141, 'num_boost_round': 242}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:51,817] Trial 25 finished with value: 30.48826712524329 and parameters: {'max_depth': 6, 'colsample_bytree': 0.5928141522004708, 'min_child_weight': 7, 'learning_rate': 0.05976449126230285, 'num_boost_round': 130}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:54,347] Trial 26 finished with value: 30.345537951370375 and parameters: {'max_depth': 4, 'colsample_bytree': 0.6785072048943946, 'min_child_weight': 9, 'learning_rate': 0.025147490251045897, 'num_boost_round': 212}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:43:59,288] Trial 27 finished with value: 30.45765691043531 and parameters: {'max_depth': 7, 'colsample_bytree': 0.6195267325972402, 'min_child_weight': 10, 'learning_rate': 0.012322151313108883, 'num_boost_round': 269}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:01,841] Trial 28 finished with value: 30.548666770052154 and parameters: {'max_depth': 8, 'colsample_bytree': 0.5285195327743777, 'min_child_weight': 9, 'learning_rate': 0.05367047969436285, 'num_boost_round': 243}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:05,066] Trial 29 finished with value: 30.62528769227717 and parameters: {'max_depth': 7, 'colsample_bytree': 0.5421797766291971, 'min_child_weight': 8, 'learning_rate': 0.020629272967204994, 'num_boost_round': 182}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:08,260] Trial 30 finished with value: 30.932103334246495 and parameters: {'max_depth': 9, 'colsample_bytree': 0.6609825099852401, 'min_child_weight': 7, 'learning_rate': 0.03609804755707688, 'num_boost_round': 137}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:10,591] Trial 31 finished with value: 30.400307857926578 and parameters: {'max_depth': 4, 'colsample_bytree': 0.6940614750176685, 'min_child_weight': 9, 'learning_rate': 0.027360766599644423, 'num_boost_round': 214}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:12,687] Trial 32 finished with value: 30.51746213085831 and parameters: {'max_depth': 4, 'colsample_bytree': 0.6489537135431775, 'min_child_weight': 9, 'learning_rate': 0.02590525674223337, 'num_boost_round': 174}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:15,664] Trial 33 finished with value: 31.701430788431935 and parameters: {'max_depth': 5, 'colsample_bytree': 0.6010895737629961, 'min_child_weight': 10, 'learning_rate': 0.008730352651991694, 'num_boost_round': 208}. Best is trial 0 with value: 30.219685552228633.\n",
      "[I 2025-01-26 18:44:18,832] Trial 34 finished with value: 30.11771537620076 and parameters: {'max_depth': 5, 'colsample_bytree': 0.6713379676343006, 'min_child_weight': 10, 'learning_rate': 0.023887524815061907, 'num_boost_round': 289}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:22,609] Trial 35 finished with value: 30.23967532947221 and parameters: {'max_depth': 5, 'colsample_bytree': 0.7576071035067716, 'min_child_weight': 10, 'learning_rate': 0.014079245513927231, 'num_boost_round': 284}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:26,485] Trial 36 finished with value: 30.20909129500172 and parameters: {'max_depth': 5, 'colsample_bytree': 0.8345455831998354, 'min_child_weight': 10, 'learning_rate': 0.013575044805256108, 'num_boost_round': 282}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:30,730] Trial 37 finished with value: 32.20725527883259 and parameters: {'max_depth': 5, 'colsample_bytree': 0.8979102335843999, 'min_child_weight': 8, 'learning_rate': 0.004537271972048948, 'num_boost_round': 300}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:35,297] Trial 38 finished with value: 30.794033962511474 and parameters: {'max_depth': 6, 'colsample_bytree': 0.8564751766367378, 'min_child_weight': 1, 'learning_rate': 0.009659355713455841, 'num_boost_round': 282}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:39,108] Trial 39 finished with value: 30.846128316487313 and parameters: {'max_depth': 5, 'colsample_bytree': 0.8884140674464565, 'min_child_weight': 10, 'learning_rate': 0.008148498264753647, 'num_boost_round': 270}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:43,224] Trial 40 finished with value: 35.58511312152838 and parameters: {'max_depth': 6, 'colsample_bytree': 0.8163694067118532, 'min_child_weight': 3, 'learning_rate': 0.002533411072276517, 'num_boost_round': 248}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:47,079] Trial 41 finished with value: 30.211725379246616 and parameters: {'max_depth': 5, 'colsample_bytree': 0.7656811776668212, 'min_child_weight': 10, 'learning_rate': 0.013986377104225293, 'num_boost_round': 284}. Best is trial 34 with value: 30.11771537620076.\n",
      "[I 2025-01-26 18:44:50,389] Trial 42 finished with value: 30.074483188912996 and parameters: {'max_depth': 5, 'colsample_bytree': 0.7841099688463887, 'min_child_weight': 10, 'learning_rate': 0.021779506146773927, 'num_boost_round': 277}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:44:53,781] Trial 43 finished with value: 30.586341127744713 and parameters: {'max_depth': 4, 'colsample_bytree': 0.788326212147875, 'min_child_weight': 10, 'learning_rate': 0.012876047416235572, 'num_boost_round': 277}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:44:56,765] Trial 44 finished with value: 30.122222534641487 and parameters: {'max_depth': 5, 'colsample_bytree': 0.8056683560653821, 'min_child_weight': 10, 'learning_rate': 0.021082089914823163, 'num_boost_round': 235}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:44:59,652] Trial 45 finished with value: 30.67207581801653 and parameters: {'max_depth': 3, 'colsample_bytree': 0.8220634673190714, 'min_child_weight': 10, 'learning_rate': 0.019625915411585267, 'num_boost_round': 263}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:45:02,866] Trial 46 finished with value: 30.22286360902901 and parameters: {'max_depth': 5, 'colsample_bytree': 0.8966386271880279, 'min_child_weight': 9, 'learning_rate': 0.01490217353812723, 'num_boost_round': 231}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:45:06,449] Trial 47 finished with value: 31.39071462841931 and parameters: {'max_depth': 4, 'colsample_bytree': 0.7706774191888659, 'min_child_weight': 10, 'learning_rate': 0.007647413270399314, 'num_boost_round': 286}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:45:09,962] Trial 48 finished with value: 30.592089100792162 and parameters: {'max_depth': 5, 'colsample_bytree': 0.7380231981557714, 'min_child_weight': 9, 'learning_rate': 0.011016696813416707, 'num_boost_round': 249}. Best is trial 42 with value: 30.074483188912996.\n",
      "[I 2025-01-26 18:45:10,342] Trial 49 finished with value: 38.63495994902136 and parameters: {'max_depth': 5, 'colsample_bytree': 0.8221542189343501, 'min_child_weight': 5, 'learning_rate': 0.017799144087502033, 'num_boost_round': 18}. Best is trial 42 with value: 30.074483188912996.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 5, 'colsample_bytree': 0.7841099688463887, 'min_child_weight': 10, 'learning_rate': 0.021779506146773927, 'num_boost_round': 277}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    params = {\n",
    "        'objective': \"reg:absoluteerror\",  # Use custom MAE objective with alpha\n",
    "        'eval_metric': 'mae',  # Mean absolute error metric for evaluation\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log = True),\n",
    "        'tree_method': 'hist',  # Use 'hist' for faster training, or 'gpu_hist' for GPU acceleration\n",
    "        'device': 'cuda',  # Use GPU if available\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 10, 300)\n",
    "    ts_split = TimeSeriesSplit(n_splits=5) \n",
    "    mae_scores = []  # To store MAE scores for each fold\n",
    "    for train_idx, val_idx in ts_split.split(X_train_selected, y_train):\n",
    "        X_train_fold, X_val_fold = X_train_selected.iloc[train_idx], X_train_selected.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train_fold, label=y_train_fold)\n",
    "        dval = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "        \n",
    "        model_xgb = xgb.train(params, dtrain, evals=[(dval, 'eval')], num_boost_round=num_boost_round, early_stopping_rounds=10, verbose_eval=False)\n",
    "        y_val_pred = model_xgb.predict(dval)\n",
    "        \n",
    "        mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    # Return the mean MAE across all folds\n",
    "    return np.mean(mae_scores)  # Optuna minimizes the objective, so we return the MAE\n",
    "\n",
    "# Create a study object and optimize it\n",
    "study = optuna.create_study(direction='minimize')  # Minimize MAE\n",
    "study.optimize(objective, n_trials=50)  # Run 50 trials\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(f\"Best Hyperparameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T18:46:21.304138Z",
     "iopub.status.busy": "2025-01-26T18:46:21.303778Z",
     "iopub.status.idle": "2025-01-26T18:46:22.143904Z",
     "shell.execute_reply": "2025-01-26T18:46:22.142242Z",
     "shell.execute_reply.started": "2025-01-26T18:46:21.304114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 16.9417\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_max_depth = best_params['max_depth']\n",
    "best_colsample_bytree = best_params['colsample_bytree']\n",
    "best_min_child_weight = best_params['min_child_weight']\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "best_num_boost_round = best_params['num_boost_round']\n",
    "\n",
    "params = {\n",
    "    'objective': \"reg:absoluteerror\",  # Use custom MAE objective with alpha\n",
    "    'eval_metric': 'mae',  # Mean absolute error metric for evaluation\n",
    "    'max_depth': best_max_depth,\n",
    "    'colsample_bytree': best_colsample_bytree,\n",
    "    'min_child_weight': best_min_child_weight,\n",
    "    'learning_rate': best_learning_rate,\n",
    "    'tree_method': 'hist',  # Use 'hist' for faster training, or 'gpu_hist' for GPU acceleration\n",
    "    'device': 'cuda',  # Use GPU if available\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_selected, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_selected, label=y_test)\n",
    "\n",
    "model_xgb = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=best_num_boost_round,  # Use the best num_boost_round from Optuna\n",
    "    evals=[(dtrain, 'train')],\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "y_test_pred = model_xgb.predict(dtest)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T19:32:16.532461Z",
     "iopub.status.busy": "2025-01-26T19:32:16.532162Z",
     "iopub.status.idle": "2025-01-26T19:32:16.539046Z",
     "shell.execute_reply": "2025-01-26T19:32:16.538164Z",
     "shell.execute_reply.started": "2025-01-26T19:32:16.532439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=100, dropout_rate=0.2):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  # Dropout layer to reduce overfitting\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, 2*hidden_dim)\n",
    "        self.fc3 = nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        \n",
    "        x = self.fc4(x) \n",
    "        x = torch.relu(x)  # Apply ReLU to ensure non-negative output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T19:14:22.052844Z",
     "iopub.status.busy": "2025-01-26T19:14:22.052493Z",
     "iopub.status.idle": "2025-01-26T19:14:22.062340Z",
     "shell.execute_reply": "2025-01-26T19:14:22.061386Z",
     "shell.execute_reply.started": "2025-01-26T19:14:22.052781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_selected = pd.concat([X_train_selected, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:03:23.783040Z",
     "iopub.status.busy": "2025-01-26T21:03:23.782704Z",
     "iopub.status.idle": "2025-01-26T21:03:23.791826Z",
     "shell.execute_reply": "2025-01-26T21:03:23.790993Z",
     "shell.execute_reply.started": "2025-01-26T21:03:23.783013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_year = 2018\n",
    "train_month = 10\n",
    "\n",
    "# Split the data based on time - use training data until June 2018 and validation data from July 2018\n",
    "train_2 = train_selected[\n",
    "    (train_selected['end_year'] < train_year) |\n",
    "    ((train_selected['end_year'] == train_year) & (train_selected['end_month'] <= train_month))\n",
    "]\n",
    "\n",
    "valid = train_selected[\n",
    "    (train_selected['start_year'] > train_year) |\n",
    "    ((train_selected['start_year'] == train_year) & (train_selected['start_month'] > train_month))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:03:41.881145Z",
     "iopub.status.busy": "2025-01-26T21:03:41.880781Z",
     "iopub.status.idle": "2025-01-26T21:03:41.886894Z",
     "shell.execute_reply": "2025-01-26T21:03:41.886187Z",
     "shell.execute_reply.started": "2025-01-26T21:03:41.881117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = train_2.drop(columns=['transactions'])  \n",
    "y_train = train_2['transactions']\n",
    "X_valid = valid.drop(columns=['transactions'])\n",
    "y_valid = valid['transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:09:04.033398Z",
     "iopub.status.busy": "2025-01-26T21:09:04.032957Z",
     "iopub.status.idle": "2025-01-26T21:09:04.050973Z",
     "shell.execute_reply": "2025-01-26T21:09:04.050181Z",
     "shell.execute_reply.started": "2025-01-26T21:09:04.033360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:03:42.414107Z",
     "iopub.status.busy": "2025-01-26T21:03:42.413805Z",
     "iopub.status.idle": "2025-01-26T21:03:42.419373Z",
     "shell.execute_reply": "2025-01-26T21:03:42.418484Z",
     "shell.execute_reply.started": "2025-01-26T21:03:42.414085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40040, 10), (40040,), (2002, 10), (2002,))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:09:55.283299Z",
     "iopub.status.busy": "2025-01-26T21:09:55.283005Z",
     "iopub.status.idle": "2025-01-26T21:09:55.291464Z",
     "shell.execute_reply": "2025-01-26T21:09:55.290542Z",
     "shell.execute_reply.started": "2025-01-26T21:09:55.283277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare the data as PyTorch tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "\n",
    "X_valid_tensor = torch.tensor(X_valid_scaled, dtype=torch.float32).to(device)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:30:21.768374Z",
     "iopub.status.busy": "2025-01-26T21:30:21.768094Z",
     "iopub.status.idle": "2025-01-26T21:30:36.424839Z",
     "shell.execute_reply": "2025-01-26T21:30:36.424084Z",
     "shell.execute_reply.started": "2025-01-26T21:30:21.768353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 46.4427, Valid Loss: 46.1950\n",
      "Epoch [2/100], Train Loss: 46.0001, Valid Loss: 46.1448\n",
      "Epoch [3/100], Train Loss: 46.5258, Valid Loss: 46.0494\n",
      "Epoch [4/100], Train Loss: 45.8298, Valid Loss: 45.8798\n",
      "Epoch [5/100], Train Loss: 45.7122, Valid Loss: 45.6033\n",
      "Epoch [6/100], Train Loss: 45.5316, Valid Loss: 45.1796\n",
      "Epoch [7/100], Train Loss: 45.0203, Valid Loss: 44.5734\n",
      "Epoch [8/100], Train Loss: 44.7417, Valid Loss: 43.7651\n",
      "Epoch [9/100], Train Loss: 44.0843, Valid Loss: 42.7379\n",
      "Epoch [10/100], Train Loss: 43.4654, Valid Loss: 41.5267\n",
      "Epoch [11/100], Train Loss: 42.5227, Valid Loss: 40.1742\n",
      "Epoch [12/100], Train Loss: 41.7892, Valid Loss: 38.6670\n",
      "Epoch [13/100], Train Loss: 40.8229, Valid Loss: 37.1567\n",
      "Epoch [14/100], Train Loss: 40.3526, Valid Loss: 35.8261\n",
      "Epoch [15/100], Train Loss: 39.4676, Valid Loss: 34.7089\n",
      "Epoch [16/100], Train Loss: 39.2531, Valid Loss: 33.8404\n",
      "Epoch [17/100], Train Loss: 38.7523, Valid Loss: 33.1087\n",
      "Epoch [18/100], Train Loss: 38.0561, Valid Loss: 32.3965\n",
      "Epoch [19/100], Train Loss: 37.6777, Valid Loss: 31.9613\n",
      "Epoch [20/100], Train Loss: 37.6759, Valid Loss: 31.6125\n",
      "Epoch [21/100], Train Loss: 37.1780, Valid Loss: 31.3866\n",
      "Epoch [22/100], Train Loss: 36.9786, Valid Loss: 31.2357\n",
      "Epoch [23/100], Train Loss: 36.5517, Valid Loss: 31.1865\n",
      "Epoch [24/100], Train Loss: 36.5408, Valid Loss: 31.2333\n",
      "Epoch [25/100], Train Loss: 36.3244, Valid Loss: 31.0512\n",
      "Epoch [26/100], Train Loss: 36.1338, Valid Loss: 31.1649\n",
      "Epoch [27/100], Train Loss: 36.1101, Valid Loss: 31.1273\n",
      "Epoch [28/100], Train Loss: 35.7438, Valid Loss: 31.1434\n",
      "Epoch [29/100], Train Loss: 35.6093, Valid Loss: 31.1825\n",
      "Epoch [30/100], Train Loss: 35.4371, Valid Loss: 31.2114\n",
      "Early stopping at epoch 30\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "model = MLPRegressor(input_dim,\n",
    "                    hidden_dim=100, \n",
    "                    dropout_rate=0.2).to(device)\n",
    "\n",
    "# Loss and optimizer (using MAE as loss function)\n",
    "criterion = nn.L1Loss()  # MAE Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=3*10**-5)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 5\n",
    "best_valid_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    # Average losses for the epoch\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    valid_loss = valid_loss / len(valid_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n",
    "    # Early stopping check\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # Save the model (optional)\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T21:30:38.851963Z",
     "iopub.status.busy": "2025-01-26T21:30:38.851579Z",
     "iopub.status.idle": "2025-01-26T21:30:38.884559Z",
     "shell.execute_reply": "2025-01-26T21:30:38.883552Z",
     "shell.execute_reply.started": "2025-01-26T21:30:38.851931Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n",
      "torch.Size([512, 10])\n",
      "torch.Size([512, 10])\n",
      "torch.Size([466, 10])\n",
      "Test MAE: 17.6504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-271-826e3d7ea663>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        print(inputs.shape)\n",
    "        outputs = model(inputs)\n",
    "        y_pred.extend(outputs.squeeze().cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6552148,
     "sourceId": 10587114,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
